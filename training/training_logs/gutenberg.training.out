torch.Size([8, 1024, 800])
torch.Size([8, 1024, 400])
tensor([[-1.6670,  0.2468,  0.1921, -0.2134,  1.4414],
        [-1.0020,  1.6211, -0.2410,  0.5978, -0.9760]], grad_fn=<AddBackward0>)
tensor([[    0.0000],
        [    0.0000]], grad_fn=<MeanBackward1>) tensor([[1.0000],
        [1.0000]], grad_fn=<VarBackward0>)
torch.Size([2, 4, 768])
torch.Size([2, 4, 768])
validation_text length = 51164551
train_loader length: 31085
validation_loader length = 3575
Epoch: 0 Step: 0 Training loss:9.617789268493652 Validation loss: 9.739094734191895
Epoch: 0 Step: 1000 Training loss:5.417124080657959 Validation loss: 5.366511726379395
Epoch: 0 Step: 2000 Training loss:4.991411972045898 Validation loss: 4.836933612823486
Epoch: 0 Step: 3000 Training loss:4.673516750335693 Validation loss: 4.639122867584229
Epoch: 0 Step: 4000 Training loss:4.567372035980225 Validation loss: 4.565092468261719
Epoch: 0 Step: 5000 Training loss:4.369308662414551 Validation loss: 4.391553211212158
Epoch: 0 Step: 6000 Training loss:4.2306239128112795 Validation loss: 4.341347503662109
Epoch: 0 Step: 7000 Training loss:4.201334857940674 Validation loss: 4.369863796234131
Epoch: 0 Step: 8000 Training loss:4.002430200576782 Validation loss: 4.177018022537231
Epoch: 0 Step: 9000 Training loss:4.107216501235962 Validation loss: 4.2695056915283205
Epoch: 0 Step: 10000 Training loss:4.014515829086304 Validation loss: 4.09988112449646
Epoch: 0 Step: 11000 Training loss:4.0031813621521 Validation loss: 4.127829360961914
Epoch: 0 Step: 12000 Training loss:3.8479382514953615 Validation loss: 4.092842054367066
Epoch: 0 Step: 13000 Training loss:3.863984966278076 Validation loss: 4.009445858001709
Epoch: 0 Step: 14000 Training loss:3.9564477443695067 Validation loss: 4.086319923400879
Epoch: 0 Step: 15000 Training loss:3.837472152709961 Validation loss: 3.9016608238220214
Epoch: 0 Step: 16000 Training loss:3.7309040069580077 Validation loss: 4.0739494323730465
Epoch: 0 Step: 17000 Training loss:3.6820523262023928 Validation loss: 4.025727653503418
Epoch: 0 Step: 18000 Training loss:3.7751655101776125 Validation loss: 3.889069604873657
Epoch: 0 Step: 19000 Training loss:3.699253273010254 Validation loss: 3.953060674667358
Epoch: 0 Step: 20000 Training loss:3.6995696067810058 Validation loss: 3.9851239204406737
Epoch: 0 Step: 21000 Training loss:3.636723756790161 Validation loss: 4.042359304428101
Epoch: 0 Step: 22000 Training loss:3.7401166439056395 Validation loss: 3.9359486579895018
Epoch: 0 Step: 23000 Training loss:3.732698392868042 Validation loss: 3.7462989330291747
Epoch: 0 Step: 24000 Training loss:3.682824897766113 Validation loss: 3.8760595321655273
Epoch: 0 Step: 25000 Training loss:3.6451586723327636 Validation loss: 3.8162862777709963
Epoch: 0 Step: 26000 Training loss:3.7452617645263673 Validation loss: 3.9089349269866944
Epoch: 0 Step: 27000 Training loss:3.506570291519165 Validation loss: 3.8624618530273436
Epoch: 0 Step: 28000 Training loss:3.6959986209869387 Validation loss: 3.8856693267822267
Epoch: 0 Step: 29000 Training loss:3.612875509262085 Validation loss: 3.8492615699768065
Epoch: 0 Step: 30000 Training loss:3.6385924339294435 Validation loss: 3.826570749282837
Epoch: 0 Step: 31000 Training loss:3.5945061683654784 Validation loss: 3.8262978076934813
Every effort moves you to the                                                
Epoch: 1 Step: 32000 Training loss:3.656558656692505 Validation loss: 3.853147792816162
Epoch: 1 Step: 33000 Training loss:3.4681973457336426 Validation loss: 3.823110008239746
Epoch: 1 Step: 34000 Training loss:3.5248170375823973 Validation loss: 3.858740282058716
Epoch: 1 Step: 35000 Training loss:3.63057222366333 Validation loss: 3.810632562637329
Epoch: 1 Step: 36000 Training loss:3.5173669815063477 Validation loss: 3.7606332302093506
Epoch: 1 Step: 37000 Training loss:3.6028474807739257 Validation loss: 3.982810926437378
Epoch: 1 Step: 38000 Training loss:3.5748178958892822 Validation loss: 3.880099153518677
Epoch: 1 Step: 39000 Training loss:3.5803001880645753 Validation loss: 3.7915955543518067
Epoch: 1 Step: 40000 Training loss:3.611526346206665 Validation loss: 3.8576755046844484
Epoch: 1 Step: 41000 Training loss:3.578794527053833 Validation loss: 3.7197289943695067
Epoch: 1 Step: 42000 Training loss:3.427439260482788 Validation loss: 3.856118392944336
Epoch: 1 Step: 43000 Training loss:3.512503147125244 Validation loss: 3.745226001739502
Epoch: 1 Step: 44000 Training loss:3.5575257778167724 Validation loss: 3.7391780853271483
Epoch: 1 Step: 45000 Training loss:3.4662903785705566 Validation loss: 3.780923271179199
Epoch: 1 Step: 46000 Training loss:3.342124652862549 Validation loss: 3.7287979125976562
Epoch: 1 Step: 47000 Training loss:3.4975976943969727 Validation loss: 3.6853497982025147
Epoch: 1 Step: 48000 Training loss:3.513573169708252 Validation loss: 3.721830654144287
Epoch: 1 Step: 49000 Training loss:3.4707162857055662 Validation loss: 3.7346198081970217
Epoch: 1 Step: 50000 Training loss:3.503137397766113 Validation loss: 3.796139144897461
Epoch: 1 Step: 51000 Training loss:3.496846151351929 Validation loss: 3.772264862060547
Epoch: 1 Step: 52000 Training loss:3.520236921310425 Validation loss: 3.8287661552429197
Epoch: 1 Step: 53000 Training loss:3.5016993045806886 Validation loss: 3.799978160858154
Epoch: 1 Step: 54000 Training loss:3.4696705818176268 Validation loss: 3.6756337165832518
Epoch: 1 Step: 55000 Training loss:3.3703487396240233 Validation loss: 3.7251452922821047
Epoch: 1 Step: 56000 Training loss:3.4189454078674317 Validation loss: 3.7972035884857176
Epoch: 1 Step: 57000 Training loss:3.454816770553589 Validation loss: 3.692704963684082
Epoch: 1 Step: 58000 Training loss:3.38189697265625 Validation loss: 3.68851580619812
Epoch: 1 Step: 59000 Training loss:3.509459972381592 Validation loss: 3.653501605987549
Epoch: 1 Step: 60000 Training loss:3.42083535194397 Validation loss: 3.660602569580078
Epoch: 1 Step: 61000 Training loss:3.3700966835021973 Validation loss: 3.6949867725372316
Epoch: 1 Step: 62000 Training loss:3.3969183921813966 Validation loss: 3.627653169631958
Every effort moves you to the right, and the right hand is placed in the right hand, and the right hand is left to the left hand, and the left hand is left to the left hand.  The right hand is left to the left hand
Epoch: 2 Step: 63000 Training loss:3.36568865776062 Validation loss: 3.7400856018066406
Epoch: 2 Step: 64000 Training loss:3.4615124702453612 Validation loss: 3.643767213821411
Epoch: 2 Step: 65000 Training loss:3.436272954940796 Validation loss: 3.7279484272003174
Epoch: 2 Step: 66000 Training loss:3.262655830383301 Validation loss: 3.6168368816375733
Epoch: 2 Step: 67000 Training loss:3.5193283557891846 Validation loss: 3.6819626808166506
Epoch: 2 Step: 68000 Training loss:3.493468761444092 Validation loss: 3.684001111984253
Epoch: 2 Step: 69000 Training loss:3.352830982208252 Validation loss: 3.7528942108154295
Epoch: 2 Step: 70000 Training loss:3.499706745147705 Validation loss: 3.6303855895996096
Epoch: 2 Step: 71000 Training loss:3.3515204906463625 Validation loss: 3.667322778701782
Epoch: 2 Step: 72000 Training loss:3.292631912231445 Validation loss: 3.6825586318969727
Epoch: 2 Step: 73000 Training loss:3.4974267959594725 Validation loss: 3.741789722442627
Epoch: 2 Step: 74000 Training loss:3.407761478424072 Validation loss: 3.731196928024292
Epoch: 2 Step: 75000 Training loss:3.338218641281128 Validation loss: 3.7257900714874266
Epoch: 2 Step: 76000 Training loss:3.445374870300293 Validation loss: 3.5501137733459474
Epoch: 2 Step: 77000 Training loss:3.4479328632354735 Validation loss: 3.678045892715454
Epoch: 2 Step: 78000 Training loss:3.449108695983887 Validation loss: 3.7488621711730956
Epoch: 2 Step: 79000 Training loss:3.3842228412628175 Validation loss: 3.592255687713623
Epoch: 2 Step: 80000 Training loss:3.458682489395142 Validation loss: 3.742758798599243
Epoch: 2 Step: 81000 Training loss:3.362337350845337 Validation loss: 3.6574466228485107
Epoch: 2 Step: 82000 Training loss:3.354255771636963 Validation loss: 3.56296763420105
Epoch: 2 Step: 83000 Training loss:3.2808337211608887 Validation loss: 3.661803197860718
Epoch: 2 Step: 84000 Training loss:3.377944564819336 Validation loss: 3.642743539810181
Epoch: 2 Step: 85000 Training loss:3.3823668003082275 Validation loss: 3.690576934814453
Epoch: 2 Step: 86000 Training loss:3.318581533432007 Validation loss: 3.720231866836548
Epoch: 2 Step: 87000 Training loss:3.3201380729675294 Validation loss: 3.624555969238281
Epoch: 2 Step: 88000 Training loss:3.363230848312378 Validation loss: 3.668455171585083
Epoch: 2 Step: 89000 Training loss:3.368818235397339 Validation loss: 3.666554307937622
Epoch: 2 Step: 90000 Training loss:3.318004608154297 Validation loss: 3.699374198913574
Epoch: 2 Step: 91000 Training loss:3.344817543029785 Validation loss: 3.6548158645629885
Epoch: 2 Step: 92000 Training loss:3.3213688373565673 Validation loss: 3.569126558303833
Epoch: 2 Step: 93000 Training loss:3.346150016784668 Validation loss: 3.5755518436431886
Every effort moves you to the right, and you can't be sure of it."  "I don't know," said the girl, "that I can't be sure of it."  "I don't know," said the girl, "that
Epoch: 3 Step: 94000 Training loss:3.377545118331909 Validation loss: 3.65736780166626
Epoch: 3 Step: 95000 Training loss:3.3641058921813967 Validation loss: 3.6930141925811766
Epoch: 3 Step: 96000 Training loss:3.3888203144073485 Validation loss: 3.5831359386444093
Epoch: 3 Step: 97000 Training loss:3.413322401046753 Validation loss: 3.6452345848083496
Epoch: 3 Step: 98000 Training loss:3.3930368423461914 Validation loss: 3.657879114151001
Epoch: 3 Step: 99000 Training loss:3.3159770011901855 Validation loss: 3.6270072937011717
Epoch: 3 Step: 100000 Training loss:3.311102771759033 Validation loss: 3.6681132316589355
Epoch: 3 Step: 101000 Training loss:3.350652647018433 Validation loss: 3.6201022148132322
Epoch: 3 Step: 102000 Training loss:3.437461757659912 Validation loss: 3.658417224884033
Epoch: 3 Step: 103000 Training loss:3.3756815433502196 Validation loss: 3.5110068798065184
Epoch: 3 Step: 104000 Training loss:3.3837156772613524 Validation loss: 3.652736759185791
Epoch: 3 Step: 105000 Training loss:3.3211972236633303 Validation loss: 3.725169372558594
Epoch: 3 Step: 106000 Training loss:3.269626092910767 Validation loss: 3.599566602706909
Epoch: 3 Step: 107000 Training loss:3.3557321548461916 Validation loss: 3.6315752029418946
Epoch: 3 Step: 108000 Training loss:3.373673439025879 Validation loss: 3.6435892581939697
Epoch: 3 Step: 109000 Training loss:3.4337071895599367 Validation loss: 3.591648578643799
Epoch: 3 Step: 110000 Training loss:3.234736776351929 Validation loss: 3.629878616333008
Epoch: 3 Step: 111000 Training loss:3.247983932495117 Validation loss: 3.6771634101867674
Epoch: 3 Step: 112000 Training loss:3.310774230957031 Validation loss: 3.6882681369781496
Epoch: 3 Step: 113000 Training loss:3.20789475440979 Validation loss: 3.7428497791290285
Epoch: 3 Step: 114000 Training loss:3.415201997756958 Validation loss: 3.6267956256866456
Epoch: 3 Step: 115000 Training loss:3.2304874420166017 Validation loss: 3.4591365814208985
Epoch: 3 Step: 116000 Training loss:3.237449598312378 Validation loss: 3.6953923225402834
Epoch: 3 Step: 117000 Training loss:3.3356631278991697 Validation loss: 3.6279880523681642
Epoch: 3 Step: 118000 Training loss:3.3445692539215086 Validation loss: 3.699675464630127
Epoch: 3 Step: 119000 Training loss:3.345941495895386 Validation loss: 3.5963149070739746
Epoch: 3 Step: 120000 Training loss:3.3677266120910643 Validation loss: 3.5810303688049316
Epoch: 3 Step: 121000 Training loss:3.315007734298706 Validation loss: 3.7221259117126464
Epoch: 3 Step: 122000 Training loss:3.26072301864624 Validation loss: 3.7232526302337647
Epoch: 3 Step: 123000 Training loss:3.3121596813201903 Validation loss: 3.619073820114136
Epoch: 3 Step: 124000 Training loss:3.4265024185180666 Validation loss: 3.6471051216125487
Every effort moves you to the right,                                              
Epoch: 4 Step: 125000 Training loss:3.2956239700317385 Validation loss: 3.6570471286773683
Epoch: 4 Step: 126000 Training loss:3.3103776931762696 Validation loss: 3.56882061958313
Epoch: 4 Step: 127000 Training loss:3.380377674102783 Validation loss: 3.6304835796356203
Epoch: 4 Step: 128000 Training loss:3.200552749633789 Validation loss: 3.694365215301514
Epoch: 4 Step: 129000 Training loss:3.225967216491699 Validation loss: 3.671351194381714
Epoch: 4 Step: 130000 Training loss:3.2226940155029298 Validation loss: 3.6805234432220457
Epoch: 4 Step: 131000 Training loss:3.302330160140991 Validation loss: 3.5864577293395996
Epoch: 4 Step: 132000 Training loss:3.2815348625183107 Validation loss: 3.6614159107208253
Epoch: 4 Step: 133000 Training loss:3.245760202407837 Validation loss: 3.6266281604766846
Epoch: 4 Step: 134000 Training loss:3.2749203205108643 Validation loss: 3.6214508533477785
Epoch: 4 Step: 135000 Training loss:3.3196911811828613 Validation loss: 3.578636407852173
Epoch: 4 Step: 136000 Training loss:3.2658231258392334 Validation loss: 3.545651578903198
Epoch: 4 Step: 137000 Training loss:3.22348313331604 Validation loss: 3.5695502758026123
Epoch: 4 Step: 138000 Training loss:3.3335103511810305 Validation loss: 3.61998929977417
Epoch: 4 Step: 139000 Training loss:3.2566372871398928 Validation loss: 3.5793330669403076
Epoch: 4 Step: 140000 Training loss:3.2813963890075684 Validation loss: 3.625566816329956
Epoch: 4 Step: 141000 Training loss:3.3061086654663088 Validation loss: 3.619528865814209
Epoch: 4 Step: 142000 Training loss:3.2834012508392334 Validation loss: 3.6694243431091307
Epoch: 4 Step: 143000 Training loss:3.339015579223633 Validation loss: 3.599821996688843
Epoch: 4 Step: 144000 Training loss:3.223474407196045 Validation loss: 3.5363142490386963
Epoch: 4 Step: 145000 Training loss:3.279930019378662 Validation loss: 3.556414985656738
Epoch: 4 Step: 146000 Training loss:3.2897480487823487 Validation loss: 3.558743381500244
Epoch: 4 Step: 147000 Training loss:3.2598228931427 Validation loss: 3.560085153579712
Epoch: 4 Step: 148000 Training loss:3.2521300315856934 Validation loss: 3.4462275981903074
Epoch: 4 Step: 149000 Training loss:3.3132187843322756 Validation loss: 3.6530779361724854
Epoch: 4 Step: 150000 Training loss:3.251258134841919 Validation loss: 3.6850601196289063
Epoch: 4 Step: 151000 Training loss:3.332251214981079 Validation loss: 3.597713804244995
Epoch: 4 Step: 152000 Training loss:3.2785714626312257 Validation loss: 3.574736309051514
Epoch: 4 Step: 153000 Training loss:3.316764068603516 Validation loss: 3.525689888000488
Epoch: 4 Step: 154000 Training loss:3.242462635040283 Validation loss: 3.5830917835235594
Epoch: 4 Step: 155000 Training loss:3.2013671875 Validation loss: 3.491829776763916
Every effort moves you to the end of the world.  "The world is not a world of the world, but a world of the world.  "The world is not a world of the world, but a world of the world.  "
[9.617789268493652, 5.417124080657959, 4.991411972045898, 4.673516750335693, 4.567372035980225, 4.369308662414551, 4.2306239128112795, 4.201334857940674, 4.002430200576782, 4.107216501235962, 4.014515829086304, 4.0031813621521, 3.8479382514953615, 3.863984966278076, 3.9564477443695067, 3.837472152709961, 3.7309040069580077, 3.6820523262023928, 3.7751655101776125, 3.699253273010254, 3.6995696067810058, 3.636723756790161, 3.7401166439056395, 3.732698392868042, 3.682824897766113, 3.6451586723327636, 3.7452617645263673, 3.506570291519165, 3.6959986209869387, 3.612875509262085, 3.6385924339294435, 3.5945061683654784, 3.656558656692505, 3.4681973457336426, 3.5248170375823973, 3.63057222366333, 3.5173669815063477, 3.6028474807739257, 3.5748178958892822, 3.5803001880645753, 3.611526346206665, 3.578794527053833, 3.427439260482788, 3.512503147125244, 3.5575257778167724, 3.4662903785705566, 3.342124652862549, 3.4975976943969727, 3.513573169708252, 3.4707162857055662, 3.503137397766113, 3.496846151351929, 3.520236921310425, 3.5016993045806886, 3.4696705818176268, 3.3703487396240233, 3.4189454078674317, 3.454816770553589, 3.38189697265625, 3.509459972381592, 3.42083535194397, 3.3700966835021973, 3.3969183921813966, 3.36568865776062, 3.4615124702453612, 3.436272954940796, 3.262655830383301, 3.5193283557891846, 3.493468761444092, 3.352830982208252, 3.499706745147705, 3.3515204906463625, 3.292631912231445, 3.4974267959594725, 3.407761478424072, 3.338218641281128, 3.445374870300293, 3.4479328632354735, 3.449108695983887, 3.3842228412628175, 3.458682489395142, 3.362337350845337, 3.354255771636963, 3.2808337211608887, 3.377944564819336, 3.3823668003082275, 3.318581533432007, 3.3201380729675294, 3.363230848312378, 3.368818235397339, 3.318004608154297, 3.344817543029785, 3.3213688373565673, 3.346150016784668, 3.377545118331909, 3.3641058921813967, 3.3888203144073485, 3.413322401046753, 3.3930368423461914, 3.3159770011901855, 3.311102771759033, 3.350652647018433, 3.437461757659912, 3.3756815433502196, 3.3837156772613524, 3.3211972236633303, 3.269626092910767, 3.3557321548461916, 3.373673439025879, 3.4337071895599367, 3.234736776351929, 3.247983932495117, 3.310774230957031, 3.20789475440979, 3.415201997756958, 3.2304874420166017, 3.237449598312378, 3.3356631278991697, 3.3445692539215086, 3.345941495895386, 3.3677266120910643, 3.315007734298706, 3.26072301864624, 3.3121596813201903, 3.4265024185180666, 3.2956239700317385, 3.3103776931762696, 3.380377674102783, 3.200552749633789, 3.225967216491699, 3.2226940155029298, 3.302330160140991, 3.2815348625183107, 3.245760202407837, 3.2749203205108643, 3.3196911811828613, 3.2658231258392334, 3.22348313331604, 3.3335103511810305, 3.2566372871398928, 3.2813963890075684, 3.3061086654663088, 3.2834012508392334, 3.339015579223633, 3.223474407196045, 3.279930019378662, 3.2897480487823487, 3.2598228931427, 3.2521300315856934, 3.3132187843322756, 3.251258134841919, 3.332251214981079, 3.2785714626312257, 3.316764068603516, 3.242462635040283, 3.2013671875]
